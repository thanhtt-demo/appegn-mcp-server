{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98f10973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain>=0.2.16 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (0.3.23)\n",
      "Requirement already satisfied: langchain-aws>=0.2.2 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (0.2.31)\n",
      "Requirement already satisfied: boto3 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (1.40.25)\n",
      "Requirement already satisfied: requests in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (4.13.3)\n",
      "Requirement already satisfied: psycopg2-binary in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (2.9.10)\n",
      "Requirement already satisfied: tqdm in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (4.1.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from langchain>=0.2.16) (0.3.75)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from langchain>=0.2.16) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from langchain>=0.2.16) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from langchain>=0.2.16) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from langchain>=0.2.16) (2.0.40)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from langchain>=0.2.16) (6.0.2)\n",
      "Requirement already satisfied: numpy<3,>=1.26.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from langchain-aws>=0.2.2) (2.2.5)\n",
      "Requirement already satisfied: botocore<1.41.0,>=1.40.25 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from boto3) (1.40.25)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from boto3) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from beautifulsoup4) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from botocore<1.41.0,>=1.40.25->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: filelock in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain>=0.2.16) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.51->langchain>=0.2.16) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain>=0.2.16) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain>=0.2.16) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain>=0.2.16) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain>=0.2.16) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.2.16) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.2.16) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain>=0.2.16) (0.4.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain>=0.2.16) (3.1.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain>=0.2.16) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain>=0.2.16) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain>=0.2.16) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain>=0.2.16) (3.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.41.0,>=1.40.25->boto3) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\thanh\\anaconda3\\envs\\python312\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain>=0.2.16) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"langchain>=0.2.16\" \"langchain-aws>=0.2.2\" boto3 requests beautifulsoup4 psycopg2-binary tqdm sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c40b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "# bedrock_pgvector_demo.py\n",
    "import os, re, json, hashlib, math\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv()\n",
    "from typing import List, Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "import boto3\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "WIKI_URL = \"https://vi.wikipedia.org/wiki/Chi%E1%BA%BFn_tranh_Vi%E1%BB%87t_Nam\"\n",
    "PG_HOST = os.getenv(\"PG_HOST\")\n",
    "PG_PORT = os.getenv(\"PG_PORT\")\n",
    "PG_DATABASE = os.getenv(\"PG_DATABASE\")\n",
    "PG_USER = os.getenv(\"PG_USER\")\n",
    "PG_PASSWORD = os.getenv(\"PG_PASSWORD\")\n",
    "REGION = os.getenv(\"AWS_REGION\")\n",
    "\n",
    "PG_DSN   = f\"postgresql://{PG_USER}:{PG_PASSWORD}@{PG_HOST}:{PG_PORT}/{PG_DATABASE}\"\n",
    "\n",
    "MODEL_ID = \"amazon.titan-embed-text-v2:0\"\n",
    "DIMS     = 1024        # 256 / 512 / 1024 (v2 hỗ trợ)  # :contentReference[oaicite:7]{index=7}\n",
    "NORMALIZE= True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fadb587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- 1) LOAD WIKI ----------\n",
    "def fetch_wiki(url: str) -> Tuple[str, str, str]:\n",
    "    \"\"\"Return title, lang, plain_text\"\"\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Bedrock-Pgvector-Demo)\"}\n",
    "    r = requests.get(url, headers=headers, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "    # Title & language\n",
    "    title = soup.find(\"h1\", id=\"firstHeading\")\n",
    "    title = title.get_text(strip=True) if title else (soup.title.get_text(strip=True) if soup.title else url)\n",
    "    html_lang = soup.find(\"html\").get(\"lang\") if soup.find(\"html\") else \"vi\"\n",
    "\n",
    "    # Lấy phần nội dung chính\n",
    "    content_div = soup.find(\"div\", id=\"mw-content-text\")\n",
    "    text = content_div.get_text(separator=\"\\n\", strip=True) if content_div else soup.get_text(\"\\n\", strip=True)\n",
    "\n",
    "    # Loại bỏ chú thích [1], [2], [...]\n",
    "    text = re.sub(r\"\\[\\d+\\]\", \"\", text)\n",
    "    # Nén khoảng trắng\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    text = re.sub(r\"\\n{2,}\", \"\\n\\n\", text).strip()\n",
    "    return title, html_lang, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c81a8a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(text: str) -> List[str]:\n",
    "    # Recursive splitter (ưu tiên giữ đoạn/câu). :contentReference[oaicite:8]{index=8}\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        # Các separator hợp với TV: đoạn, dòng, câu, từ\n",
    "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "        chunk_size=1000,       # theo ký tự (ổn định đa ngôn ngữ)\n",
    "        chunk_overlap=150,\n",
    "        length_function=len,\n",
    "        add_start_index=False\n",
    "    )\n",
    "    chunks = [c.page_content for c in splitter.create_documents([text])]\n",
    "    # Lọc chunk “quá ngắn” vô nghĩa\n",
    "    chunks = [c for c in chunks if len(c) >= 50]\n",
    "    return chunks\n",
    "\n",
    "# ---------- 3) EMBEDDINGS ----------\n",
    "def bedrock_embedder():\n",
    "    client = boto3.client(\"bedrock-runtime\", region_name=REGION)\n",
    "    return BedrockEmbeddings(\n",
    "        client=client,\n",
    "        model_id=MODEL_ID,\n",
    "        model_kwargs={\n",
    "            \"dimensions\": DIMS,    # 256/512/1024\n",
    "            \"normalize\": NORMALIZE # chuẩn hóa để dùng cosine hoặc inner product\n",
    "        }\n",
    "    )\n",
    "\n",
    "def embed_texts(embedder, texts: List[str]) -> List[List[float]]:\n",
    "    # LangChain sẽ gọi Bedrock runtime theo batches\n",
    "    return embedder.embed_documents(texts)\n",
    "\n",
    "def embed_query(embedder, text: str) -> List[float]:\n",
    "    return embedder.embed_query(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b102ec3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def db_connect():\n",
    "    return psycopg2.connect(PG_DSN)\n",
    "\n",
    "def upsert_document(conn, url: str, title: str, lang: str, checksum: bytes) -> int:\n",
    "    with conn, conn.cursor() as cur:\n",
    "        cur.execute(\"\"\"\n",
    "            INSERT INTO rag.document (source_url, title, language, checksum)\n",
    "            VALUES (%s, %s, %s, %s)\n",
    "            ON CONFLICT (source_url) DO UPDATE\n",
    "              SET title = EXCLUDED.title, language = EXCLUDED.language, checksum = EXCLUDED.checksum\n",
    "            RETURNING id\n",
    "        \"\"\", (url, title, lang, psycopg2.Binary(checksum)))\n",
    "        doc_id = cur.fetchone()[0]\n",
    "        return doc_id\n",
    "\n",
    "def insert_chunks(conn, doc_id: int, chunks: List[str], vectors: List[List[float]]):\n",
    "    # Chèn bulk; pgvector literal là chuỗi '[v1,v2,...]'\n",
    "    rows = []\n",
    "    for i, (txt, vec) in enumerate(zip(chunks, vectors)):\n",
    "        vec_str = \"[\" + \",\".join(f\"{x:.7f}\" for x in vec) + \"]\"\n",
    "        rows.append((\n",
    "            doc_id, i, txt, None, len(txt), vec_str\n",
    "        ))\n",
    "    with conn, conn.cursor() as cur:\n",
    "        execute_values(cur, \"\"\"\n",
    "            INSERT INTO rag.chunk (document_id, ordinal, content, n_tokens, char_count, embedding)\n",
    "            VALUES %s\n",
    "        \"\"\", rows)\n",
    "\n",
    "# ---------- 5) SEARCH ----------\n",
    "def semantic_search(conn, query_vec: List[float], top_k=5):\n",
    "    vec_str = \"[\" + \",\".join(f\"{x:.7f}\" for x in query_vec) + \"]\"\n",
    "    sql = \"\"\"\n",
    "        SELECT id, content,\n",
    "               1 - (embedding <=> %s::vector) AS cosine_similarity\n",
    "        FROM rag.chunk\n",
    "        ORDER BY embedding <=> %s::vector ASC\n",
    "        LIMIT %s\n",
    "    \"\"\"\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(sql, (vec_str, vec_str, top_k))\n",
    "        return cur.fetchall()\n",
    "\n",
    "\n",
    "def hybrid_search(conn, query_text: str, query_vec: List[float], top_k=5, rrf_k=60):\n",
    "    \"\"\"\n",
    "    Reciprocal Rank Fusion (RRF): f = 1/(K + rank)\n",
    "    K ~ 60 là con số thực nghiệm phổ biến.\n",
    "    \"\"\"\n",
    "    vec_str = \"[\" + \",\".join(f\"{x:.7f}\" for x in query_vec) + \"]\"\n",
    "    sql = f\"\"\"\n",
    "    WITH sem AS (\n",
    "      SELECT id, content,\n",
    "             ROW_NUMBER() OVER (ORDER BY embedding <=> %s::vector ASC) AS rnk_sem\n",
    "      FROM rag.chunk\n",
    "      LIMIT 200\n",
    "    ),\n",
    "    fts AS (\n",
    "      SELECT id, content,\n",
    "             ROW_NUMBER() OVER (ORDER BY ts_rank_cd(content_tsv, plainto_tsquery('simple', %s)) DESC) AS rnk_fts\n",
    "      FROM rag.chunk\n",
    "      WHERE content_tsv @@ plainto_tsquery('simple', %s)\n",
    "      LIMIT 200\n",
    "    ),\n",
    "    combo AS (\n",
    "      SELECT COALESCE(sem.id, fts.id) AS id,\n",
    "             COALESCE(sem.content, fts.content) AS content,\n",
    "             (CASE WHEN sem.rnk_sem IS NULL THEN 0 ELSE 1.0/(%s + sem.rnk_sem) END) +\n",
    "             (CASE WHEN fts.rnk_fts IS NULL THEN 0 ELSE 1.0/(%s + fts.rnk_fts) END) AS rrf\n",
    "      FROM sem FULL OUTER JOIN fts USING (id)\n",
    "    )\n",
    "    SELECT id, content\n",
    "    FROM combo\n",
    "    ORDER BY rrf DESC\n",
    "    LIMIT %s;\n",
    "    \"\"\"\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(sql, (vec_str, query_text, query_text, rrf_k, rrf_k, top_k))\n",
    "        return cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e88e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Tải Wikipedia ==\n",
      "Title: Chiến tranh Việt Nam | Lang: vi | Length: 364953 chars\n",
      "== Chia chunks bằng LangChain ==\n",
      "Chunks: 458\n"
     ]
    }
   ],
   "source": [
    "print(\"== Tải Wikipedia ==\")\n",
    "title, lang, text = fetch_wiki(WIKI_URL)\n",
    "checksum = hashlib.sha256(text.encode(\"utf-8\")).digest()\n",
    "print(f\"Title: {title} | Lang: {lang} | Length: {len(text)} chars\")\n",
    "\n",
    "print(\"== Chia chunks bằng LangChain ==\")\n",
    "chunks = split_text(text)\n",
    "print(f\"Chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d61eec31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Khởi tạo Bedrock Embeddings ==\n",
      "== Tạo embeddings ==\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error raised by inference endpoint\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\thanh\\anaconda3\\envs\\python312\\Lib\\site-packages\\langchain_aws\\embeddings\\bedrock.py\", line 198, in _invoke_model\n",
      "    response = self.client.invoke_model(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\thanh\\anaconda3\\envs\\python312\\Lib\\site-packages\\botocore\\client.py\", line 602, in _api_call\n",
      "    return self._make_api_call(operation_name, kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\thanh\\anaconda3\\envs\\python312\\Lib\\site-packages\\botocore\\context.py\", line 123, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\thanh\\anaconda3\\envs\\python312\\Lib\\site-packages\\botocore\\client.py\", line 1078, in _make_api_call\n",
      "    raise error_class(parsed_response, operation_name)\n",
      "botocore.errorfactory.ValidationException: An error occurred (ValidationException) when calling the InvokeModel operation: The provided model identifier is invalid.\n"
     ]
    },
    {
     "ename": "ValidationException",
     "evalue": "An error occurred (ValidationException) when calling the InvokeModel operation: The provided model identifier is invalid.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m embedder = bedrock_embedder()\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m== Tạo embeddings ==\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m vectors = \u001b[43membed_texts\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m== Kết nối Postgres ==\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m conn = db_connect()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36membed_texts\u001b[39m\u001b[34m(embedder, texts)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_texts\u001b[39m(embedder, texts: List[\u001b[38;5;28mstr\u001b[39m]) -> List[List[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# LangChain sẽ gọi Bedrock runtime theo batches\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43membedder\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thanh\\anaconda3\\envs\\python312\\Lib\\site-packages\\langchain_aws\\embeddings\\bedrock.py:231\u001b[39m, in \u001b[36mBedrockEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embed_cohere_documents(texts)\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iteratively_embed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thanh\\anaconda3\\envs\\python312\\Lib\\site-packages\\langchain_aws\\embeddings\\bedrock.py:244\u001b[39m, in \u001b[36mBedrockEmbeddings._iteratively_embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    242\u001b[39m results = []\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.normalize:\n\u001b[32m    247\u001b[39m         response = \u001b[38;5;28mself\u001b[39m._normalize_vector(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thanh\\anaconda3\\envs\\python312\\Lib\\site-packages\\langchain_aws\\embeddings\\bedrock.py:167\u001b[39m, in \u001b[36mBedrockEmbeddings._embedding_func\u001b[39m\u001b[34m(self, text, input_type)\u001b[39m\n\u001b[32m    164\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response_body.get(\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# includes common provider == \"amazon\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     response_body = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_invoke_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minputText\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response_body.get(\u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thanh\\anaconda3\\envs\\python312\\Lib\\site-packages\\langchain_aws\\embeddings\\bedrock.py:209\u001b[39m, in \u001b[36mBedrockEmbeddings._invoke_model\u001b[39m\u001b[34m(self, input_body)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    208\u001b[39m     logger.exception(\u001b[33m\"\u001b[39m\u001b[33mError raised by inference endpoint\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thanh\\anaconda3\\envs\\python312\\Lib\\site-packages\\langchain_aws\\embeddings\\bedrock.py:198\u001b[39m, in \u001b[36mBedrockEmbeddings._invoke_model\u001b[39m\u001b[34m(self, input_body)\u001b[39m\n\u001b[32m    195\u001b[39m body = json.dumps(input_body)\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodelId\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontentType\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m     response_body = json.loads(response.get(\u001b[33m\"\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m\"\u001b[39m).read())\n\u001b[32m    206\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response_body\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thanh\\anaconda3\\envs\\python312\\Lib\\site-packages\\botocore\\client.py:602\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    599\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    600\u001b[39m     )\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thanh\\anaconda3\\envs\\python312\\Lib\\site-packages\\botocore\\context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\thanh\\anaconda3\\envs\\python312\\Lib\\site-packages\\botocore\\client.py:1078\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1074\u001b[39m     error_code = request_context.get(\n\u001b[32m   1075\u001b[39m         \u001b[33m'\u001b[39m\u001b[33merror_code_override\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1076\u001b[39m     ) \u001b[38;5;129;01mor\u001b[39;00m error_info.get(\u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1077\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1080\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[31mValidationException\u001b[39m: An error occurred (ValidationException) when calling the InvokeModel operation: The provided model identifier is invalid."
     ]
    }
   ],
   "source": [
    "print(\"== Khởi tạo Bedrock Embeddings ==\")\n",
    "embedder = bedrock_embedder()\n",
    "\n",
    "print(\"== Tạo embeddings ==\")\n",
    "vectors = embed_texts(embedder, chunks)\n",
    "print(\"== Kết nối Postgres ==\")\n",
    "conn = db_connect()\n",
    "\n",
    "print(\"== Upsert document & insert chunks ==\")\n",
    "doc_id = upsert_document(conn, WIKI_URL, title, lang, checksum)\n",
    "insert_chunks(conn, doc_id, chunks, vectors)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b2da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"== Truy vấn thử (semantic) ==\")\n",
    "q = \"Nguyên nhân và diễn biến chính của Chiến tranh Việt Nam là gì?\"\n",
    "qvec = embed_query(embedder, q)\n",
    "rows = semantic_search(conn, qvec, top_k=5)\n",
    "for rid, content, sim in rows:\n",
    "    print(f\"\\n[#{rid}] cos_sim={sim:.4f}\\n{content[:300]}...\")\n",
    "\n",
    "print(\"\\n== Truy vấn thử (hybrid RRF) ==\")\n",
    "rows = hybrid_search(conn, q, qvec, top_k=5)\n",
    "for rid, content in rows:\n",
    "    print(f\"\\n[#{rid}] {content[:300]}...\")\n",
    "\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
